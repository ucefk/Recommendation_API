{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8005961b-514a-4132-8668-d5fd6a4915cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Building a Real-time Recommendation API\n",
    "\n",
    "This reference architecture shows the full lifecycle of building a recommendation system. It walks through the creation of appropriate azure resources, training a recommendation model using a Virtual Machine or Databricks, and deploying it as an API. It uses Azure Cosmos DB, Azure Machine Learning, and Azure Kubernetes Service. \n",
    "\n",
    "This architecture can be generalized for many recommendation engine scenarios, including recommendations for products, movies, and news. \n",
    "### Architecture\n",
    "![architecture](img/reco-arch.png \"Architecture\")\n",
    "\n",
    "**Scenario**: A media organization wants to provide movie or video recommendations to its users. By providing personalized recommendations, the organization meets several business goals, including increased click-through rates, increased engagement on site, and higher user satisfaction.\n",
    "\n",
    "In this reference, we train and deploy a real-time recommender service API that can provide the top 10 movie recommendations for a given user. \n",
    "\n",
    "### Dataflow\n",
    "1. Track user behaviors. For example, a back-end service might log when a user rates a movie or clicks a product or news article.\n",
    "2. Load the data into Azure Databricks from an available [data source](https://learn.microsoft.com/en-us/azure/databricks/data/data-sources/).\n",
    "3. Prepare the data and split it into training and testing sets to train the model. ([This guide](https://github.com/Microsoft/Recommenders/blob/master/examples/01_prepare_data/data_split.ipynb) describes options for splitting data.)\n",
    "4. Fit the [Spark Collaborative Filtering](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html) model to the data.\n",
    "5. Evaluate the quality of the model using rating and ranking metrics. ([This guide](https://github.com/Microsoft/Recommenders/blob/master/examples/03_evaluate/evaluation.ipynb) provides details about the metrics that you can use to evaluate your recommender.)\n",
    "6. Precompute the top 10 recommendations per user and store as a cache in Azure Cosmos DB.\n",
    "7. Deploy an API service to AKS using the Machine Learning APIs to containerize and deploy the API.\n",
    "8. When the back-end service gets a request from a user, call the recommendations API hosted in AKS to get the top 10 recommendations and display them to the user.\n",
    "\n",
    "### Components\n",
    "This architecture consists of the following key components:\n",
    "* [Azure Databricks](https://docs.microsoft.com/en-us/azure/azure-databricks/what-is-azure-databricks)<sup>1)</sup> is used as a development environment to prepare input data and train the recommender model on a Spark cluster. Azure Databricks also provides an interactive workspace to run and collaborate on notebooks for any data processing or machine learning tasks.\n",
    "* [Azure Kubernetes Service](https://docs.microsoft.com/en-us/azure/aks/intro-kubernetes)(AKS) is used to deploy and operationalize a machine learning model service API on a Kubernetes cluster. AKS hosts the containerized model, providing scalability that meets throughput requirements, identity and access management, and logging and health monitoring. \n",
    "* [Azure Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/introduction) is a globally distributed database service used to store the top 10 recommended movies for each user. Azure Cosmos DB is ideal for this scenario as it provides low latency (10 ms at 99th percentile) to read the top recommended items for a given user. \n",
    "* [Azure Machine Learning Service](https://docs.microsoft.com/en-us/azure/machine-learning/service/) is a service used to track and manage machine learning models, and then package and deploy these models to a scalable Azure Kubernetes Service environment.\n",
    "\n",
    "\n",
    "### Table of Contents.\n",
    "0. [File Imports](#0-File-Imports)\n",
    "1. [Service Creation](#1-Service-Creation)\n",
    "2. [Training and evaluation](#2-Training)\n",
    "3. [Operationalization](#3.-Operationalize-the-Recommender-Service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33e61a7b-fb2e-4714-9255-8215c138e7d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Setup\n",
    "To run this notebook on Azure Databricks, you should setup Azure Databricks by following the appropriate sections in the repository [SETUP instructions](https://raw.githubusercontent.com/microsoft/recommenders/main/SETUP.md) and import this notebook into your Azure Databricks Workspace (see instructions [here](https://docs.azuredatabricks.net/user-guide/notebooks/notebook-manage.html#import-a-notebook)).\n",
    "\n",
    "Please note: This notebook **REQUIRES** that you add the dependencies to support **operationalization**. See [SETUP](https://raw.githubusercontent.com/microsoft/recommenders/main/SETUP.md) for details.\n",
    "\n",
    "![libraries](img/databricks.jpg \"Libraries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68da0ebf-2a16-4892-8a86-3d274a07283d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 0 File Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9f0defa-bddb-4cde-8ab2-8885020a6704",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "238329c4-ea86-4f5b-993d-d5a147c7711f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.common.client_factory import get_client_from_cli_profile\n",
    "\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "import azure.mgmt.cosmosdb\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "from azureml.core import Environment\n",
    "from azureml.core.environment import CondaDependencies\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import SparkPackage\n",
    "\n",
    "import pydocumentdb.document_client as document_client\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import FloatType, IntegerType, LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "232456a4-7723-49bc-b49a-d1f760bfff64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.cosmos_cli import find_collection, read_collection, read_database, find_database\n",
    "from recommenders.datasets.download_utils import maybe_download\n",
    "from recommenders.datasets.spark_splitters import spark_random_split\n",
    "from recommenders.evaluation.spark_evaluation import SparkRatingEvaluation, SparkRankingEvaluation\n",
    "from recommenders.utils.notebook_utils import is_databricks\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.utils.spark_utils import start_or_get_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdc112c5-8d39-43fc-a9ab-0bff9892ea54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Azure SDK version: 1.48.0\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Azure SDK version: 1.48.0\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Azure SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc07f8cc-276f-4b0d-943b-097e8932af91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SparkContext master=local[*, 4] appName=Databricks Shell>\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<SparkContext master=local[*, 4] appName=Databricks Shell>\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start spark session if needed\n",
    "if not is_databricks():\n",
    "    cosmos_connector = (\n",
    "        \"https://search.maven.org/remotecontent?filepath=com/azure/cosmos/spark/\"\n",
    "        \"azure-cosmos-spark_3-1_2-12/4.15.0/azure-cosmos-spark_3-1_2-12-4.15.0.jar\"\n",
    "    )\n",
    "    jar_filepath = maybe_download(url=cosmos_connector, filename=\"cosmos.jar\")\n",
    "    spark = start_or_get_spark(\"ALS\", memory=\"10g\", jars=[jar_filepath])\n",
    "    sc = spark.sparkContext\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "764fcccb-ec31-42eb-8f1b-732d406e7eba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1 Service Creation\n",
    "Modify the **Subscription ID** to the subscription you would like to deploy to and set the resource name variables.\n",
    "\n",
    "#### Services created by this notebook:\n",
    "1. [Azure ML Service](https://azure.microsoft.com/en-us/services/machine-learning-service/)\n",
    "    1. [Azure ML Workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace)\n",
    "    1. [Azure Application Insights](https://azure.microsoft.com/en-us/services/monitor/)\n",
    "    1. [Azure Storage](https://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview)\n",
    "    1. [Azure Key Vault](https://azure.microsoft.com/en-us/services/key-vault/)    \n",
    "\n",
    "1. [Azure Cosmos DB](https://azure.microsoft.com/en-us/services/cosmos-db/)\n",
    "1. [Azure Kubernetes Service (AKS)](https://azure.microsoft.com/en-us/services/kubernetes-service/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61ae42df-c6c1-4841-895c-5e9ef5224670",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Add your Azure subscription ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe6606b2-4a8a-400f-ad56-b2cf9eb63128",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add your subscription ID\n",
    "subscription_id = \"my-subscription-id\"\n",
    "\n",
    "# Set your workspace name\n",
    "workspace_name = \"databricks-project\"\n",
    "resource_group = \"DatabricksProjectRG\"#\"{}-rg\".format(workspace_name)\n",
    "\n",
    "# Set your region to deploy Azure ML workspace\n",
    "location = \"eastus\"\n",
    "\n",
    "# AzureML service and Azure Kubernetes Service prefix\n",
    "service_name = \"mvl-als\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "977166c9-627d-436a-b48b-6dea2b11accd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[93mTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code F874G9FCP to authenticate.\u001b[0m\r\n",
       "[\r\n",
       "  {\r\n",
       "    \"cloudName\": \"AzureCloud\",\r\n",
       "    \"homeTenantId\": \"home-tenant-id\",\r\n",
       "    \"id\": \"my-subscription-id\",\r\n",
       "    \"isDefault\": true,\r\n",
       "    \"managedByTenants\": [\r\n",
       "      {\r\n",
       "        \"tenantId\": \"tenant-id\"\r\n",
       "      }\r\n",
       "    ],\r\n",
       "    \"name\": \"Azure for Students\",\r\n",
       "    \"state\": \"Enabled\",\r\n",
       "    \"tenantId\": \"home-tenant-id\",\r\n",
       "    \"user\": {\r\n",
       "      \"name\": \"my-email\",\r\n",
       "      \"type\": \"user\"\r\n",
       "    }\r\n",
       "  }\r\n",
       "]\r\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\u001b[93mTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code F874G9FCP to authenticate.\u001b[0m\r\n[\r\n  {\r\n    \"cloudName\": \"AzureCloud\",\r\n    \"homeTenantId\": \"home-tenant-id\",\r\n    \"id\": \"my-subscription-id\",\r\n    \"isDefault\": true,\r\n    \"managedByTenants\": [\r\n      {\r\n        \"tenantId\": \"tenant-id\"\r\n      }\r\n    ],\r\n    \"name\": \"Azure for Students\",\r\n    \"state\": \"Enabled\",\r\n    \"tenantId\": \"home-tenant-id\",\r\n    \"user\": {\r\n      \"name\": \"my-email\",\r\n      \"type\": \"user\"\r\n    }\r\n  }\r\n]\r\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Login for Azure CLI so that AzureML can use Azure CLI login credentials\n",
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28257f59-0b7a-464d-8fa7-2d2de8ef01a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Change subscription if needed\n",
    "!az account set --subscription {subscription_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51e228fc-ef4b-4d47-9a47-38b44fd8c5ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\r\n",
       "  \"environmentName\": \"AzureCloud\",\r\n",
       "  \"homeTenantId\": \"home-tenant-id\",\r\n",
       "  \"id\": \"my-subscription-id\",\r\n",
       "  \"isDefault\": true,\r\n",
       "  \"managedByTenants\": [\r\n",
       "    {\r\n",
       "      \"tenantId\": \"tenant-id\"\r\n",
       "    }\r\n",
       "  ],\r\n",
       "  \"name\": \"Azure for Students\",\r\n",
       "  \"state\": \"Enabled\",\r\n",
       "  \"tenantId\": \"home-tenant-id\",\r\n",
       "  \"user\": {\r\n",
       "    \"name\": \"my-email\",\r\n",
       "    \"type\": \"user\"\r\n",
       "  }\r\n",
       "}\r\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "{\r\n  \"environmentName\": \"AzureCloud\",\r\n  \"homeTenantId\": \"home-tenant-id\",\r\n  \"id\": \"my-subscription-id\",\r\n  \"isDefault\": true,\r\n  \"managedByTenants\": [\r\n    {\r\n      \"tenantId\": \"tenant-id\"\r\n    }\r\n  ],\r\n  \"name\": \"Azure for Students\",\r\n  \"state\": \"Enabled\",\r\n  \"tenantId\": \"home-tenant-id\",\r\n  \"user\": {\r\n    \"name\": \"my-email\",\r\n    \"type\": \"user\"\r\n  }\r\n}\r\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check account\n",
    "!az account show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdbad767-d80c-48a8-b9e4-80bb101fc46a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CosmosDB\n",
    "# account_name for CosmosDB cannot have \"_\" and needs to be less than 31 chars\n",
    "account_name = \"{}-ds-sql\".format(workspace_name).replace(\"_\", \"-\")[:31]\n",
    "cosmos_database = \"recommendations\"\n",
    "cosmos_collection = \"user_recommendations_als\"\n",
    "\n",
    "# AzureML resource names\n",
    "model_name = \"{}-reco.mml\".format(service_name)\n",
    "aks_name = \"{}-aks\".format(service_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "091089fe-59ab-4be5-b3b2-9bc6e6caf08e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db353f18-b259-473c-baf2-5320ea742c44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "userCol = \"UserId\"\n",
    "itemCol = \"MovieId\"\n",
    "ratingCol = \"Rating\"\n",
    "\n",
    "train_data_path = \"train\"\n",
    "test_data_path = \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a108f0e7-1c08-469f-9323-c7cc8d3cb600",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1.1 Import or create the AzureML Workspace. \n",
    "This command will check if the AzureML Workspace exists or not, and will create the workspace if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c788c05-6fc2-4505-b4bf-dac21b50292e",
     "showTitle": false,
     "title": ""
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WARNING:root:Warning: Falling back to use azure cli login credentials.\n",
       "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
       "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "WARNING:root:Warning: Falling back to use azure cli login credentials.\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\nPlease refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ws = Workspace.create(\n",
    "    name=workspace_name,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group=resource_group, \n",
    "    location=location,\n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c0f7b03-6d50-4ff7-bcb3-cb576d777d42",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1.2 Create a Cosmos DB to store recommendation results\n",
    "\n",
    "This step will take some time to create CosmosDB resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6dbd728-77da-43aa-a98f-e6ab4f2cfab2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database found\n",
       "Collection found\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Database found\nCollection found\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explicitly pass subscription_id in case user has multiple subscriptions\n",
    "# client = get_client_from_cli_profile(\n",
    "#     azure.mgmt.cosmosdb.CosmosDB,\n",
    "#     subscription_id=subscription_id\n",
    "# )\n",
    "\n",
    "client = azure.mgmt.cosmosdb.CosmosDBManagementClient(AzureCliCredential(), subscription_id)\n",
    "\n",
    "async_cosmosdb_create = client.database_accounts.begin_create_or_update(\n",
    "    resource_group,\n",
    "    account_name,\n",
    "    {\n",
    "        'location': location,\n",
    "        'locations': [{\n",
    "            'location_name': location\n",
    "        }]\n",
    "    }\n",
    ")\n",
    "account = async_cosmosdb_create.result()\n",
    "\n",
    "my_keys = client.database_accounts.list_keys(resource_group, account_name)\n",
    "master_key = my_keys.primary_master_key\n",
    "endpoint = \"https://\" + account_name + \".documents.azure.com:443/\"\n",
    "\n",
    "# DB client\n",
    "client = document_client.DocumentClient(endpoint, {'masterKey': master_key})\n",
    "\n",
    "if not find_database(client, cosmos_database):\n",
    "    db = client.CreateDatabase({'id': cosmos_database })\n",
    "    print(\"Database created\")\n",
    "else:\n",
    "    db = read_database(client, cosmos_database)\n",
    "    print(\"Database found\")\n",
    "\n",
    "# Create collection options\n",
    "options = dict(offerThroughput=11000)\n",
    "\n",
    "# Create a collection\n",
    "collection_definition = {\n",
    "    'id': cosmos_collection,\n",
    "    'partitionKey': {'paths': ['/id'],'kind': 'Hash'}\n",
    "}\n",
    "if not find_collection(client, cosmos_database, cosmos_collection):\n",
    "    collection = client.CreateCollection(\n",
    "        db['_self'], \n",
    "        collection_definition,\n",
    "        options\n",
    "    )\n",
    "    print(\"Collection created\")\n",
    "else:\n",
    "    collection = read_collection(client, cosmos_database, cosmos_collection)\n",
    "    print(\"Collection found\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8df12834-a2bf-4636-ad58-f44f88f3493a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbsecrets = dict(\n",
    "#     Endpoint=endpoint, \n",
    "#     Masterkey=master_key, \n",
    "#     Database=cosmos_database, \n",
    "#     Collection=cosmos_collection, \n",
    "#     Upsert=True\n",
    "# )\n",
    "\n",
    "# dbsecrets = {\n",
    "#     \"accountEndpoint\" : endpoint, \n",
    "#     \"Masterkey\" : master_key, \n",
    "#     \"Database\" : cosmos_database, \n",
    "#     \"Collection\" : cosmos_collection, \n",
    "#     \"Upsert\" : True\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5e5e531-323a-4548-b1a6-1ca5144de711",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2 Training\n",
    "\n",
    "Next, we train an [Alternating Least Squares model](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html) on [MovieLens](https://grouplens.org/datasets/movielens/) dataset.\n",
    "\n",
    "### 2.1 Download the MovieLens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81f6bd66-4d2b-4be6-9527-18c804c21db6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\r",
       "  0%|          | 0.00/4.81k [00:00<?, ?KB/s]\r",
       "  4%|▎         | 177/4.81k [00:00<00:03, 1.49kKB/s]\r",
       " 30%|███       | 1.45k/4.81k [00:00<00:00, 7.65kKB/s]\r",
       "100%|██████████| 4.81k/4.81k [00:00<00:00, 17.6kKB/s]\n",
       "+------+-------+------+\n",
       "|UserId|MovieId|Rating|\n",
       "+------+-------+------+\n",
       "|   196|    242|   3.0|\n",
       "|   186|    302|   3.0|\n",
       "|    22|    377|   1.0|\n",
       "|   244|     51|   2.0|\n",
       "|   166|    346|   1.0|\n",
       "|   298|    474|   4.0|\n",
       "|   115|    265|   2.0|\n",
       "|   253|    465|   5.0|\n",
       "|   305|    451|   3.0|\n",
       "|     6|     86|   3.0|\n",
       "|    62|    257|   2.0|\n",
       "|   286|   1014|   5.0|\n",
       "|   200|    222|   5.0|\n",
       "|   210|     40|   3.0|\n",
       "|   224|     29|   3.0|\n",
       "|   303|    785|   3.0|\n",
       "|   122|    387|   5.0|\n",
       "|   194|    274|   2.0|\n",
       "|   291|   1042|   4.0|\n",
       "|   234|   1184|   2.0|\n",
       "+------+-------+------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\r  0%|          | 0.00/4.81k [00:00<?, ?KB/s]\r  4%|▎         | 177/4.81k [00:00<00:03, 1.49kKB/s]\r 30%|███       | 1.45k/4.81k [00:00<00:00, 7.65kKB/s]\r100%|██████████| 4.81k/4.81k [00:00<00:00, 17.6kKB/s]\n+------+-------+------+\n|UserId|MovieId|Rating|\n+------+-------+------+\n|   196|    242|   3.0|\n|   186|    302|   3.0|\n|    22|    377|   1.0|\n|   244|     51|   2.0|\n|   166|    346|   1.0|\n|   298|    474|   4.0|\n|   115|    265|   2.0|\n|   253|    465|   5.0|\n|   305|    451|   3.0|\n|     6|     86|   3.0|\n|    62|    257|   2.0|\n|   286|   1014|   5.0|\n|   200|    222|   5.0|\n|   210|     40|   3.0|\n|   224|     29|   3.0|\n|   303|    785|   3.0|\n|   122|    387|   5.0|\n|   194|    274|   2.0|\n|   291|   1042|   4.0|\n|   234|   1184|   2.0|\n+------+-------+------+\nonly showing top 20 rows\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note: The DataFrame-based API for ALS currently only supports integers for user and item ids.\n",
    "schema = StructType(\n",
    "    (\n",
    "        StructField(userCol, IntegerType()),\n",
    "        StructField(itemCol, IntegerType()),\n",
    "        StructField(ratingCol, FloatType()),\n",
    "    )\n",
    ")\n",
    "\n",
    "data = movielens.load_spark_df(spark, size=MOVIELENS_DATA_SIZE, schema=schema, dbutils=dbutils)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53d3835a-8a8c-45cc-8e0c-8817d23c313b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.2 Split the data into train, test\n",
    "There are several ways of splitting the data: random, chronological, stratified, etc., each of which favors a different real-world evaluation use case. We will split randomly in this example – for more details on which splitter to choose, consult [this guide](https://raw.githubusercontent.com/microsoft/recommenders/main/examples/01_prepare_data/data_split.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5624ce93-8209-4878-bb5e-09fc91f3c090",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N train 74998\n",
       "N test 25002\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "N train 74998\nN test 25002\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test = spark_random_split(data, ratio=0.75, seed=42)\n",
    "print(\"N train\", train.cache().count())\n",
    "print(\"N test\", test.cache().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6bf58810-0a1f-461a-83a9-9d2351a1c4c4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.3 Train the ALS model on the training data\n",
    "\n",
    "To predict movie ratings, we use the rating data in the training set as users' explicit feedback. The hyperparameters used to estimate the model are set based on [this page](http://mymedialite.net/examples/datasets.html).\n",
    "\n",
    "Under most circumstances, you would explore the hyperparameters and choose an optimal set based on some criteria. For additional details on this process, please see additional information in the deep dives [here](https://raw.githubusercontent.com/microsoft/recommenders/main/examples/04_model_select_and_optimize/tuning_spark_als.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6c8eeeb-75b4-4cdb-9bef-1d8652aa7e65",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "    rank=10,\n",
    "    maxIter=15,\n",
    "    implicitPrefs=False,\n",
    "    alpha=0.1,\n",
    "    regParam=0.05,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=True,\n",
    "    userCol=userCol,\n",
    "    itemCol=itemCol,\n",
    "    ratingCol=ratingCol,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82dddfc4-8225-4234-93d3-c9e854131571",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48b8130e-2441-4089-844d-7665de993937",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.4 Get top-k recommendations for our testing data\n",
    "\n",
    "In the movie recommendation use case, recommending movies that have been rated by the users do not make sense. Therefore, the rated movies are removed from the recommended items.\n",
    "\n",
    "In order to achieve this, we recommend all movies to all users, and then remove the user-movie pairs that exist in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6ef9ed5-804b-453f-9b92-8f1faa869692",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+------+-------+----------+\n",
       "|UserId|MovieId|prediction|\n",
       "+------+-------+----------+\n",
       "|   148|    148| 3.5317662|\n",
       "|   148|    471| 3.1172194|\n",
       "|   148|    496| 3.3190777|\n",
       "|   148|    463|  4.757464|\n",
       "|   148|    833|   3.68779|\n",
       "|   148|   1238| 1.8957852|\n",
       "|   148|   1088| 4.5473194|\n",
       "|   148|   1342|  1.493924|\n",
       "|   148|   1580|0.57647055|\n",
       "|   148|   1591| 3.5548735|\n",
       "|   148|    243| 2.7581022|\n",
       "|   148|    392| 3.5030882|\n",
       "|   148|    540|  2.205358|\n",
       "|   148|    737|  3.483089|\n",
       "|   148|    858| 0.9696207|\n",
       "|   148|    897|0.79084826|\n",
       "|   148|   1025| 3.0202923|\n",
       "|   148|   1084|  4.958096|\n",
       "|   148|    623|  3.010971|\n",
       "|   148|   1127| 2.4659214|\n",
       "+------+-------+----------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+------+-------+----------+\n|UserId|MovieId|prediction|\n+------+-------+----------+\n|   148|    148| 3.5317662|\n|   148|    471| 3.1172194|\n|   148|    496| 3.3190777|\n|   148|    463|  4.757464|\n|   148|    833|   3.68779|\n|   148|   1238| 1.8957852|\n|   148|   1088| 4.5473194|\n|   148|   1342|  1.493924|\n|   148|   1580|0.57647055|\n|   148|   1591| 3.5548735|\n|   148|    243| 2.7581022|\n|   148|    392| 3.5030882|\n|   148|    540|  2.205358|\n|   148|    737|  3.483089|\n|   148|    858| 0.9696207|\n|   148|    897|0.79084826|\n|   148|   1025| 3.0202923|\n|   148|   1084|  4.958096|\n|   148|    623|  3.010971|\n|   148|   1127| 2.4659214|\n+------+-------+----------+\nonly showing top 20 rows\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the cross join of all user-item pairs and score them.\n",
    "users = train.select(userCol).distinct()\n",
    "items = train.select(itemCol).distinct()\n",
    "user_item = users.crossJoin(items)\n",
    "dfs_pred = model.transform(user_item)\n",
    "dfs_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c446835f-5400-4210-896a-eeea6b4e5d1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+------+-------+----------+\n",
       "|UserId|MovieId|prediction|\n",
       "+------+-------+----------+\n",
       "|     1|      7| 4.1338468|\n",
       "|     1|      9| 4.3809776|\n",
       "|     1|     20| 3.6322436|\n",
       "|     1|     43| 2.6116803|\n",
       "|     1|     46| 3.6096683|\n",
       "|     1|     63| 2.2370367|\n",
       "|     1|    117|  3.333944|\n",
       "|     1|    118| 2.6852312|\n",
       "|     1|    119|  4.625972|\n",
       "|     1|    190|  4.299953|\n",
       "|     1|    193| 4.1029973|\n",
       "|     1|    255| 3.2740529|\n",
       "|     1|    269|  4.250825|\n",
       "|     1|    276| 4.0782523|\n",
       "|     1|    278| 1.9464829|\n",
       "|     1|    284| 3.0049326|\n",
       "|     1|    285| 4.5487285|\n",
       "|     1|    293|  4.090019|\n",
       "|     1|    294| 3.0005083|\n",
       "|     1|    300|  3.499889|\n",
       "+------+-------+----------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+------+-------+----------+\n|UserId|MovieId|prediction|\n+------+-------+----------+\n|     1|      7| 4.1338468|\n|     1|      9| 4.3809776|\n|     1|     20| 3.6322436|\n|     1|     43| 2.6116803|\n|     1|     46| 3.6096683|\n|     1|     63| 2.2370367|\n|     1|    117|  3.333944|\n|     1|    118| 2.6852312|\n|     1|    119|  4.625972|\n|     1|    190|  4.299953|\n|     1|    193| 4.1029973|\n|     1|    255| 3.2740529|\n|     1|    269|  4.250825|\n|     1|    276| 4.0782523|\n|     1|    278| 1.9464829|\n|     1|    284| 3.0049326|\n|     1|    285| 4.5487285|\n|     1|    293|  4.090019|\n|     1|    294| 3.0005083|\n|     1|    300|  3.499889|\n+------+-------+----------+\nonly showing top 20 rows\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove seen items.\n",
    "as_pred = dfs_pred.alias(\"pred\")\n",
    "as_train = train.alias(\"train\")\n",
    "\n",
    "dfs_pred_exclude_train = as_pred.join(\n",
    "    as_train,\n",
    "    (as_pred[userCol]==as_train[userCol]) & (as_pred[itemCol]==as_train[itemCol]),\n",
    "    how='outer'\n",
    ")\n",
    "top_all = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[\"train.\"+ratingCol].isNull()) \\\n",
    "    .select(\"pred.\"+userCol, \"pred.\"+itemCol, \"pred.prediction\")\n",
    "\n",
    "top_all.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dbd017c-cf74-42f9-9eb1-2461fae56e13",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.5 Evaluate how well ALS performs\n",
    "\n",
    "Evaluate model performance using metrics such as Precision@K, Recall@K, [MAP@K](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval) or [nDCG@K](https://en.wikipedia.org/wiki/Discounted_cumulative_gain). For a full guide on what metrics to evaluate your recommender with, consult [this guide]../03_evaluate/evaluation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2f0d818-d180-43e0-a26d-8ce52b77b3fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+------+-------+------+\n",
       "|UserId|MovieId|Rating|\n",
       "+------+-------+------+\n",
       "|     1|      3|   4.0|\n",
       "|     1|      7|   4.0|\n",
       "|     1|      9|   5.0|\n",
       "|     1|     10|   3.0|\n",
       "|     1|     14|   5.0|\n",
       "|     1|     20|   4.0|\n",
       "|     1|     24|   3.0|\n",
       "|     1|     30|   3.0|\n",
       "|     1|     31|   3.0|\n",
       "|     1|     33|   4.0|\n",
       "|     1|     35|   1.0|\n",
       "|     1|     36|   2.0|\n",
       "|     1|     43|   4.0|\n",
       "|     1|     46|   4.0|\n",
       "|     1|     47|   4.0|\n",
       "|     1|     48|   5.0|\n",
       "|     1|     50|   5.0|\n",
       "|     1|     52|   4.0|\n",
       "|     1|     56|   4.0|\n",
       "|     1|     63|   2.0|\n",
       "+------+-------+------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+------+-------+------+\n|UserId|MovieId|Rating|\n+------+-------+------+\n|     1|      3|   4.0|\n|     1|      7|   4.0|\n|     1|      9|   5.0|\n|     1|     10|   3.0|\n|     1|     14|   5.0|\n|     1|     20|   4.0|\n|     1|     24|   3.0|\n|     1|     30|   3.0|\n|     1|     31|   3.0|\n|     1|     33|   4.0|\n|     1|     35|   1.0|\n|     1|     36|   2.0|\n|     1|     43|   4.0|\n|     1|     46|   4.0|\n|     1|     47|   4.0|\n|     1|     48|   5.0|\n|     1|     50|   5.0|\n|     1|     52|   4.0|\n|     1|     56|   4.0|\n|     1|     63|   2.0|\n+------+-------+------+\nonly showing top 20 rows\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = {\n",
    "    'col_user': userCol,\n",
    "    'col_item': itemCol,\n",
    "    'col_rating': ratingCol,\n",
    "    'col_prediction': \"prediction\",\n",
    "}\n",
    "\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b2c0278-cb8b-4430-9036-88122d794f1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/databricks/spark/python/pyspark/sql/context.py:165: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
       "  warnings.warn(\n",
       "Model:\tALS\n",
       "Top K:\t10\n",
       "MAP:\t0.002992\n",
       "NDCG:\t0.029724\n",
       "Precision@K:\t0.035737\n",
       "Recall@K:\t0.013052\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "/databricks/spark/python/pyspark/sql/context.py:165: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  warnings.warn(\nModel:\tALS\nTop K:\t10\nMAP:\t0.002992\nNDCG:\t0.029724\nPrecision@K:\t0.035737\nRecall@K:\t0.013052\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate Ranking Metrics\n",
    "rank_eval = SparkRankingEvaluation(\n",
    "    test, \n",
    "    top_all, \n",
    "    k=TOP_K,\n",
    "    **cols\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Model:\\tALS\",\n",
    "    \"Top K:\\t%d\" % rank_eval.k,\n",
    "    \"MAP:\\t%f\" % rank_eval.map_at_k(),\n",
    "    \"NDCG:\\t%f\" % rank_eval.ndcg_at_k(),\n",
    "    \"Precision@K:\\t%f\" % rank_eval.precision_at_k(),\n",
    "    \"Recall@K:\\t%f\" % rank_eval.recall_at_k(), sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "044fd771-0df7-431c-a8dc-b375e0a7bf69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model:\tALS rating prediction\n",
       "RMSE:\t0.95\n",
       "MAE:\t0.741856\n",
       "Explained variance:\t0.293860\n",
       "R squared:\t0.289563\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Model:\tALS rating prediction\nRMSE:\t0.95\nMAE:\t0.741856\nExplained variance:\t0.293860\nR squared:\t0.289563\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate Rating Metrics\n",
    "prediction = model.transform(test)\n",
    "rating_eval = SparkRatingEvaluation(\n",
    "    test, \n",
    "    prediction, \n",
    "    **cols\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Model:\\tALS rating prediction\",\n",
    "    \"RMSE:\\t%.2f\" % rating_eval.rmse(),\n",
    "    \"MAE:\\t%f\" % rating_eval.mae(),\n",
    "    \"Explained variance:\\t%f\" % rating_eval.exp_var(),\n",
    "    \"R squared:\\t%f\" % rating_eval.rsquared(), sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f596719-6110-42a1-9474-32846e46497f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.6 Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6eaff3d7-0871-445a-9c99-8c47275d04a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Out[24]: pyspark.ml.recommendation.ALSModel"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Out[24]: pyspark.ml.recommendation.ALSModel",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e358b2e3-e7cc-4376-b318-62c14d2fba48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Out[25]: 'mvl-als-reco.mml'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Out[25]: 'mvl-als-reco.mml'",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aaf2ab8b-3878-4249-9ded-122c03bc757d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(model\n",
    " .write()\n",
    " .overwrite()\n",
    " .save(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c29c1b3b-0e5f-48e6-8e99-51a18be7e213",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Operationalize the Recommender Service\n",
    "Once the model is built with desirable performance, it will be operationalized to run as a REST endpoint to be utilized by a real time service. We will utilize [Azure Cosmos DB](https://azure.microsoft.com/en-us/services/cosmos-db/), [Azure Machine Learning Service](https://azure.microsoft.com/en-us/services/machine-learning-service/), and [Azure Kubernetes Service](https://docs.microsoft.com/en-us/azure/aks/intro-kubernetes) to operationalize the recommender service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "989897ac-43dd-4978-bf9a-3731edad7ff0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3.1 Create a look-up for Recommendations in Cosmos DB\n",
    "\n",
    "First, the Top-10 recommendations for each user as predicted by the model are stored as a lookup table in Cosmos DB. At runtime, the service will return the Top-10 recommendations as precomputed and stored in Cosmos DB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63a1f17f-ab0b-4fb9-8123-ba94c0d5b717",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---+--------------------+\n",
       "| id|             MovieId|\n",
       "+---+--------------------+\n",
       "|  1|[1643, 1449, 408,...|\n",
       "|  3|[1368, 1512, 320,...|\n",
       "|  6|[1643, 1062, 1126...|\n",
       "| 12|[1612, 1245, 645,...|\n",
       "| 13|[1643, 1347, 1062...|\n",
       "| 16|[1643, 1449, 1467...|\n",
       "| 20|[394, 1427, 538, ...|\n",
       "| 22|[1643, 50, 1269, ...|\n",
       "| 26|[1643, 1449, 114,...|\n",
       "| 27|[1368, 1085, 1449...|\n",
       "| 28|[695, 1449, 169, ...|\n",
       "| 31|[1154, 1062, 1643...|\n",
       "| 34|[1512, 1203, 1368...|\n",
       "| 40|[1643, 1612, 958,...|\n",
       "| 44|[1643, 50, 408, 1...|\n",
       "| 47|[838, 1643, 1591,...|\n",
       "| 52|[1449, 1612, 64, ...|\n",
       "| 53|[1449, 496, 318, ...|\n",
       "| 54|[914, 899, 1268, ...|\n",
       "| 57|[1612, 1643, 1005...|\n",
       "+---+--------------------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+---+--------------------+\n| id|             MovieId|\n+---+--------------------+\n|  1|[1643, 1449, 408,...|\n|  3|[1368, 1512, 320,...|\n|  6|[1643, 1062, 1126...|\n| 12|[1612, 1245, 645,...|\n| 13|[1643, 1347, 1062...|\n| 16|[1643, 1449, 1467...|\n| 20|[394, 1427, 538, ...|\n| 22|[1643, 50, 1269, ...|\n| 26|[1643, 1449, 114,...|\n| 27|[1368, 1085, 1449...|\n| 28|[695, 1449, 169, ...|\n| 31|[1154, 1062, 1643...|\n| 34|[1512, 1203, 1368...|\n| 40|[1643, 1612, 958,...|\n| 44|[1643, 50, 408, 1...|\n| 47|[838, 1643, 1591,...|\n| 52|[1449, 1612, 64, ...|\n| 53|[1449, 496, 318, ...|\n| 54|[914, 899, 1268, ...|\n| 57|[1612, 1643, 1005...|\n+---+--------------------+\nonly showing top 20 rows\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "recs = model.recommendForAllUsers(10)\n",
    "recs_topk = recs.withColumn(\"id\", recs[userCol].cast(\"string\")) \\\n",
    "    .select(\"id\", \"recommendations.\" + itemCol)\n",
    "recs_topk.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "713a8cf6-695a-4f6a-94ff-f208a5664e7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbsecrets = {\n",
    "    \"spark.cosmos.accountEndpoint\" : endpoint, \n",
    "    \"spark.cosmos.accountKey\" : master_key, \n",
    "    \"spark.cosmos.database\" : cosmos_database, \n",
    "    \"spark.cosmos.container\" : cosmos_collection, \n",
    "    \"Upsert\" : True\n",
    "}\n",
    "\n",
    "\n",
    "# Save data to CosmosDB\n",
    "(recs_topk.coalesce(1)\n",
    " .write\n",
    " .format(\"cosmos.oltp\")\n",
    " .mode('Append')\n",
    " .options(**dbsecrets)\n",
    " .save())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a455a071-73c0-4529-b5cc-365d472b93b7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3.2 Configure Azure Machine Learning\n",
    "\n",
    "Next, Azure Machine Learning Service is used to create a model scoring image and deploy it to Azure Kubernetes Service as a scalable containerized service. To achieve this, a **scoring script** should be created. In the script, we make a call to Cosmos DB to lookup the top 10 movies to recommend given an input User ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8d64f65-6efb-474f-8fae-8d26fd787408",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "score_sparkml = \"\"\"\n",
    "import json\n",
    "import pydocumentdb.document_client as document_client\n",
    "\n",
    "def init(local=False):\n",
    "    global client, collection\n",
    "    try:\n",
    "        client = document_client.DocumentClient('{endpoint}', dict(masterKey='{key}'))\n",
    "        collection = client.ReadCollection(collection_link='dbs/{database}/colls/{collection}')\n",
    "    except Exception as e:\n",
    "        collection = e\n",
    "\n",
    "def run(input_json):\n",
    "    try:\n",
    "        # Query them in SQL\n",
    "        id = str(json.loads(json.loads(input_json)[0])['id'])\n",
    "        query = dict(query='SELECT * FROM c WHERE c.id = \"' + id +'\"')\n",
    "        options = dict(partitionKey=str(id))\n",
    "        document_link = 'dbs/{database}/colls/{collection}/docs/' + id\n",
    "        result = client.ReadDocument(document_link, options);  \n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "    return json.dumps(str(result))\n",
    "\"\"\".format(key=dbsecrets['spark.cosmos.accountKey'], \n",
    "           endpoint=dbsecrets['spark.cosmos.accountEndpoint'], \n",
    "           database=dbsecrets['spark.cosmos.database'], \n",
    "           collection=dbsecrets['spark.cosmos.container'])\n",
    "\n",
    "# test validity of python string\n",
    "exec(score_sparkml)\n",
    "\n",
    "with open(\"score_sparkml.py\", \"w\") as file:\n",
    "    file.write(score_sparkml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f12ebf2c-5813-40c0-b613-7a3d206d6853",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Register your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea848e9c-53b5-48c6-a484-3c010260b277",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pyspark.ml.recommendation.ALSModel'>\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<class 'pyspark.ml.recommendation.ALSModel'>\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "049f300e-820f-4299-adc7-0bd1d50ff740",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Out[31]: 'mvl-als-reco.mml'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Out[31]: 'mvl-als-reco.mml'",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "390b0d56-487d-4927-b639-3eff28a0a432",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mvl-als-reco.mml/itemFactors/</td><td>itemFactors/</td><td>0</td><td>1672557970000</td></tr><tr><td>dbfs:/mvl-als-reco.mml/metadata/</td><td>metadata/</td><td>0</td><td>1672557964000</td></tr><tr><td>dbfs:/mvl-als-reco.mml/userFactors/</td><td>userFactors/</td><td>0</td><td>1672557968000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mvl-als-reco.mml/itemFactors/",
         "itemFactors/",
         0,
         1672557970000
        ],
        [
         "dbfs:/mvl-als-reco.mml/metadata/",
         "metadata/",
         0,
         1672557964000
        ],
        [
         "dbfs:/mvl-als-reco.mml/userFactors/",
         "userFactors/",
         0,
         1672557968000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls('/mvl-als-reco.mml/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c30118b-effb-4c45-afba-bdd9dc6ec383",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileStore   databricks-datasets  mvl-als-reco\t   mvl-als-recommend\r\n",
       "databricks  databricks-results\t mvl-als-reco.mml  tmp\r\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "FileStore   databricks-datasets  mvl-als-reco\t   mvl-als-recommend\r\ndatabricks  databricks-results\t mvl-als-reco.mml  tmp\r\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!ls /dbfs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddb8f6c3-20d6-4c2a-8e93-b672bc91c5b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Registering model mvl-als-reco.mml\n",
       "mvl-als-reco.mml AML trained model 3\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Registering model mvl-als-reco.mml\nmvl-als-reco.mml AML trained model 3\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mymodel = Model.register(\n",
    "    model_path='/dbfs/' + model_name + '/',  # this points to a local file\n",
    "    model_name=model_name,  # this is the name the model is registered as\n",
    "    description=\"AML trained model\",\n",
    "    workspace=ws\n",
    ")\n",
    "\n",
    "print(mymodel.name, mymodel.description, mymodel.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f947bc6-81ea-4b21-a003-4953af3ca145",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3.3 Deploy the model as a Service on AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f02805a8-e8a1-4ce7-9b7e-9580a52fe98a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.3.1 Create an Environment for your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6ccccb5-5879-4b5a-ab4d-c0484fe5cba0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "env = Environment(name='sparkmlenv')\n",
    "\n",
    "# Specify a public image from microsoft/mmlspark as base image\n",
    "env.docker.base_image=\"microsoft/mmlspark:0.15\"\n",
    "\n",
    "pip = [\n",
    "    'azureml-defaults', \n",
    "    'numpy==1.14.2', \n",
    "    'scikit-learn==0.19.1', \n",
    "    'pandas', \n",
    "    'pydocumentdb'\n",
    "]\n",
    "\n",
    "# Add dependencies needed for inferencing\n",
    "env.python.conda_dependencies = CondaDependencies.create(pip_packages=pip)\n",
    "env.inferencing_stack_version = \"latest\"\n",
    "\n",
    "# Add spark packages\n",
    "env.spark.precache_packages = True\n",
    "env.spark.repositories = [\"https://mmlspark.azureedge.net/maven\"]\n",
    "env.spark.packages= [\n",
    "    SparkPackage(\"com.microsoft.ml.spark\", \"mmlspark_2.11\", \"0.15\"),\n",
    "    SparkPackage(\"com.microsoft.azure\", artifact=\"azure-storage\", version=\"2.0.0\"),\n",
    "    SparkPackage(group=\"org.apache.hadoop\", artifact=\"hadoop-azure\", version=\"2.7.0\")\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcd56ce9-899b-43c5-a96a-1bb891d1ab42",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.3.2 Create an AKS Cluster to run your container\n",
    "This may take 20 to 30 minutes depending on the cluster size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52dfc75b-658f-4d6d-bf6c-5b8ed317c422",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deploying AppInsights with name databricinsights276fe04f.\n",
       "Deployed AppInsights with name databricinsights276fe04f. Took 6.24 seconds.\n",
       "Deploying KeyVault with name databrickeyvaultc2154c27.\n",
       "Deploying StorageAccount with name databricstorage8a15bd358.\n",
       "Deployed KeyVault with name databrickeyvaultc2154c27. Took 22.24 seconds.\n",
       "Deployed StorageAccount with name databricstorage8a15bd358. Took 25.35 seconds.\n",
       "Deploying Workspace with name databricks-project.\n",
       "Deployed Workspace with name databricks-project. Took 19.26 seconds.\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Deploying AppInsights with name databricinsights276fe04f.\nDeployed AppInsights with name databricinsights276fe04f. Took 6.24 seconds.\nDeploying KeyVault with name databrickeyvaultc2154c27.\nDeploying StorageAccount with name databricstorage8a15bd358.\nDeployed KeyVault with name databrickeyvaultc2154c27. Took 22.24 seconds.\nDeployed StorageAccount with name databricstorage8a15bd358. Took 25.35 seconds.\nDeploying Workspace with name databricks-project.\nDeployed Workspace with name databricks-project. Took 19.26 seconds.\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resource_group2 = \"DatabricksProjectRG2\"\n",
    "\n",
    "location2 = \"uksouth\"\n",
    "\n",
    "ws2 = Workspace.create(\n",
    "    name=workspace_name,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group=resource_group2, \n",
    "    location=location2,\n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b8c7fee-f7a4-4bd2-86b4-17512473e1f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Registering model mvl-als-reco.mml\n",
       "mvl-als-reco.mml AML trained model 1\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Registering model mvl-als-reco.mml\nmvl-als-reco.mml AML trained model 1\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mymodel = Model.register(\n",
    "    model_path='/dbfs/' + model_name + '/',  # this points to a local file\n",
    "    model_name=model_name,  # this is the name the model is registered as\n",
    "    description=\"AML trained model\",\n",
    "    workspace=ws2\n",
    ")\n",
    "\n",
    "print(mymodel.name, mymodel.description, mymodel.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fba6126e-8f11-4964-8c6c-a9991ef32546",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Creating.......................................................................................................\n",
       "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
       "Succeeded\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Creating.......................................................................................................\nSucceededProvisioning operation finished, operation \"Succeeded\"\nSucceeded\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
    "    print(\"Found existing cluster, use it.\")\n",
    "except ComputeTargetException:\n",
    "    # Create the cluster using the default configuration (can also provide parameters to customize)\n",
    "    prov_config = AksCompute.provisioning_configuration()\n",
    "    aks_target = ComputeTarget.create(\n",
    "        workspace=ws, \n",
    "        name=aks_name, \n",
    "        provisioning_configuration=prov_config\n",
    "    )\n",
    "    aks_target.wait_for_completion(show_output = True)\n",
    "    print(aks_target.provisioning_state)\n",
    "    # To check any error logs, print(aks_target.provisioning_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "722239ac-df74-4ed3-83f7-1af75de65396",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running....................................................................................................................\n",
       "SucceededAKS service creation operation finished, operation \"Succeeded\"\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Running....................................................................................................................\nSucceededAKS service creation operation finished, operation \"Succeeded\"\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an Inferencing Configuration with your environment and scoring script\n",
    "inference_config = InferenceConfig(\n",
    "    environment=env,\n",
    "    entry_script=\"score_sparkml.py\"\n",
    ")\n",
    "\n",
    "# Set the web service configuration (using default here with app insights)\n",
    "aks_config = AksWebservice.deploy_configuration(enable_app_insights=True)\n",
    "\n",
    "# Webservice creation using single command\n",
    "try:\n",
    "    aks_service = Model.deploy(\n",
    "        workspace=ws,\n",
    "        models=[mymodel],\n",
    "        name=service_name,\n",
    "        inference_config=inference_config,\n",
    "        deployment_config=aks_config,\n",
    "        deployment_target=aks_target\n",
    "    )\n",
    "    aks_service.wait_for_deployment(show_output=True)\n",
    "except WebserviceException:\n",
    "    # Retrieve existing service.\n",
    "    aks_service = Webservice(ws, name=service_name)\n",
    "    print(\"Retrieved existing service\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47ad5026-80b1-4679-98a1-e7f34fe3195e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3.4 Call the AKS model service\n",
    "After the deployment, the service can be called with a user ID – the service will then look up the top 10 recommendations for that user in Cosmos DB and send back the results.\n",
    "The following script demonstrates how to call the recommendation service API and view the result for the given user ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d92fd74d-9c9d-4680-9134-c97c3dc13ec2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"MovieId\": [\n",
       "        320,\n",
       "        1589,\n",
       "        262,\n",
       "        1344,\n",
       "        958,\n",
       "        889,\n",
       "        1368,\n",
       "        645,\n",
       "        919,\n",
       "        1137\n",
       "    ],\n",
       "    \"id\": \"496\",\n",
       "    \"_rid\": \"34hEAIe9pterAQAAAAAACA==\",\n",
       "    \"_self\": \"dbs/34hEAA==/colls/34hEAIe9ptc=/docs/34hEAIe9pterAQAAAAAACA==/\",\n",
       "    \"_etag\": \"6d006b74-0000-0100-0000-5f25f0550000\",\n",
       "    \"_attachments\": \"attachments/\",\n",
       "    \"_ts\": 1596321877\n",
       "}\n",
       "Full run took 0.05 seconds\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "{\n    \"MovieId\": [\n        320,\n        1589,\n        262,\n        1344,\n        958,\n        889,\n        1368,\n        645,\n        919,\n        1137\n    ],\n    \"id\": \"496\",\n    \"_rid\": \"34hEAIe9pterAQAAAAAACA==\",\n    \"_self\": \"dbs/34hEAA==/colls/34hEAIe9ptc=/docs/34hEAIe9pterAQAAAAAACA==/\",\n    \"_etag\": \"6d006b74-0000-0100-0000-5f25f0550000\",\n    \"_attachments\": \"attachments/\",\n    \"_ts\": 1596321877\n}\nFull run took 0.05 seconds\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "scoring_url = aks_service.scoring_uri\n",
    "service_key = aks_service.get_keys()[0]\n",
    "\n",
    "input_data = '[\"{\\\\\"id\\\\\":\\\\\"496\\\\\"}\"]'.encode()\n",
    "\n",
    "req = urllib.request.Request(scoring_url, data=input_data)\n",
    "req.add_header(\"Authorization\",\"Bearer {}\".format(service_key))\n",
    "req.add_header(\"Content-Type\",\"application/json\")\n",
    "\n",
    "with Timer() as t: \n",
    "    with urllib.request.urlopen(req) as result:\n",
    "        res = result.read()\n",
    "        resj = json.loads(\n",
    "            # Cleanup to parse into a json object\n",
    "            res.decode(\"utf-8\")\n",
    "            .replace(\"\\\\\", \"\")\n",
    "            .replace('\"', \"\")\n",
    "            .replace(\"'\", '\"')\n",
    "        )\n",
    "        print(json.dumps(resj, indent=4))\n",
    "    \n",
    "print(\"Full run took %.2f seconds\" % t.interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b33a29e2-754b-4b16-b4ab-4e1ac40d2041",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Appendix - Realtime scoring with AzureML\n",
    "\n",
    "In the previous cells, we utilized Cosmos DB to cache the recommendation results for realtime serving. Alternatively, we can generate recommendation results on demand by using the model we deployed. Following scripts load the registered model and use it for recommendation:\n",
    "\n",
    "* *score_sparkml.py*\n",
    "    ```\n",
    "    import json\n",
    "    import os\n",
    "    from pyspark.ml.recommendation import ALSModel\n",
    "\n",
    "    # Note, set `model_name`, `userCol`, and `itemCol` defined earlier.\n",
    "    model_name = \"mvl-als-reco.mml\"\n",
    "    userCol = \"UserId\"\n",
    "    itemCol = \"MovieId\"\n",
    "\n",
    "    def init(local=False):\n",
    "        global model\n",
    "\n",
    "        # Load ALS model.\n",
    "        model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), model_name)\n",
    "        model = ALSModel.load(model_path)\n",
    "\n",
    "    def run(input_json):\n",
    "        js = json.loads(json.loads(input_json)[0])\n",
    "        id = str(js['id'])\n",
    "        k = js.get('k', 10)\n",
    "\n",
    "        # Use the model to get recommendation.\n",
    "        recs = model.recommendForAllUsers(k)\n",
    "        recs_topk = recs.withColumn('id', recs[userCol].cast(\"string\")).select(\n",
    "            'id', \"recommendations.\" + itemCol\n",
    "        )\n",
    "        result = recs_topk[recs_topk.id==id].collect()[0].asDict()\n",
    "\n",
    "        return json.dumps(str(result))\n",
    "    ```\n",
    "\n",
    "* Call the AKS model service\n",
    "    ```\n",
    "    # Get a recommendation of 10 movies\n",
    "    input_data = '[\"{\\\\\"id\\\\\":\\\\\"496\\\\\",\\\\\"k\\\\\":10}\"]'.encode()\n",
    "\n",
    "    req = urllib.request.Request(scoring_url, data=input_data)\n",
    "    req.add_header(\"Authorization\",\"Bearer {}\".format(service_key))\n",
    "    req.add_header(\"Content-Type\",\"application/json\")\n",
    "    \n",
    "    ...\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "661b4d08-6499-4b46-a661-f605ef7a3934",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "als_movie_reco",
   "notebookOrigID": 327856643391471,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "name": "ALS_Movie_Example",
  "notebookId": 3793436040750096,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
